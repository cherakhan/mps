"""
  Implements some example discriminative models.
  -- kandasamy@cs.cmu.edu
"""

# pylint: disable=invalid-name
# pylint: disable=abstract-method
# pylint: disable=no-member

from copy import deepcopy
import numpy as np
# Local
from exd.domains import EuclideanDomain
from prob.prob_distros import ParametricDiscriminativeModel, BayesianDiscriminativeModel
try:
  from prob.edward_prob_distros import EdwardBayesianDiscriminativeModel
except ImportError:
  EdwardBayesianDiscriminativeModel = None


class LogisticWithGaussianNoise(ParametricDiscriminativeModel):
  """ An example demonstrating a logistic with Gaussian Noise.
      Precisely, implements f(x) = a/(1 + exp(b(x-c))), and y = f(x) + e where
      e~N(0,eta2).
  """

  def __init__(self, a, b, c, eta2, x_domain=None, *args, **kwargs):
    """ Constructor. """
    theta = [a, b, c, eta2]
    if x_domain is None:
      x_domain = EuclideanDomain([[-np.inf, np.inf]])
    y_domain = EuclideanDomain([[-np.inf, np.inf]])
    super(LogisticWithGaussianNoise, self).__init__(x_domain, y_domain, theta,
                                                    None, *args, **kwargs)

  def _eval_fx(self, X):
    """ Evaluates f(x) = a/(1 + exp(b(x-c))). """
    a = self.theta[0]
    b = self.theta[1]
    c = self.theta[2]
    X_ = np.array(X).ravel()
    return a/(1 + np.exp(b * (X_ - c)))

  def _sample_y_giv_x_single(self, num_samples, x):
    """ Samples y given x. """
    mean_val = self._eval_fx(x)
    ret = mean_val + np.sqrt(self.theta[3]) * np.random.normal(size=(num_samples,))
    return ret

  def eval_y_mean_giv_x(self, X):
    """ Evaluate the mean. """
    return list(self._eval_fx(X))

  def eval_y_var_giv_x(self, X):
    """ Evaluate the variance. """
    return list(self.theta[3] * np.ones((len(X),)))

  def eval_y_covar_giv_x(self, X):
    """ Evaluate the covariance. """
    return np.diag(self.eval_y_var_giv_x(X))

  def __str__(self):
    """ Returns a string representation. """
    return ('LogisticWithGaussian: a=%0.3f, b=%.3f, c=%.3f, eta2=%0.3f'%(
            self.theta[0], self.theta[1], self.theta[2], self.theta[3]))


class BayesianLogisticWithGaussianNoise(EdwardBayesianDiscriminativeModel):
  """ An example similar to LogisticWithGaussianNoise but a, b, c, eta2 are
      drawn from a prior.
  """

  def __init__(self, x_domain, t_domain, prior_info, *args, **kwargs):
    """ Constructor. See EdwardBayesianDiscriminativeModel for details. """
    if x_domain is None:
      x_domain = EuclideanDomain([[-np.inf, np.inf]])
    if t_domain is None:
      t_domain = EuclideanDomain([[-np.inf, np.inf]] * 3 + [[0, np.inf]])
    y_domain = EuclideanDomain([[-np.inf, np.inf]])
    super(BayesianLogisticWithGaussianNoise, self).__init__(y_domain, x_domain, t_domain,
                                                            prior_info, *args, **kwargs)

  @classmethod
  def get_param_vector_from_dict(cls, param_dict):
    """ Returns the parameter vector from a dictionary representation. """
    return [param_dict['a'], param_dict['b'], param_dict['c'], param_dict['eta2']]

  @classmethod
  def get_param_dict_from_vector(cls, param_vector):
    """ Returns the parameter as a dictionaryfrom a vector representation. """
    return {'a':param_vector[0], 'b':param_vector[1], 'c':param_vector[2],
            'eta2':param_vector[3]}

  def get_edward_distribution_for_y_given_x_t(self, param_distros, X_data):
    """ Returns the discriminative distribution in Edward. """
    loc = self._compute_fx(X_data, param_distros['a'], param_distros['b'],
                           param_distros['c'])
    num_data = int(X_data.shape[0])
    scale = self.tf.sqrt(param_distros['eta2']) * self.tf.ones(num_data)
    return self.ed.models.Normal(loc=loc, scale=scale)

  def _compute_fx(self, X_data, a, b, c):
    """ Computes f(x). """
#     ret = a / (1 + self.tf.exp(b*(self.tf.reshape(X_data, [-1]) - c)))
    D = int(X_data.shape[1])
    ret = self.tf.divide(a, 1+self.tf.exp(b*(self.ed.dot(X_data, self.tf.ones(D))-c)))
    return ret

  def _draw_single_sample_from_posterior(self, posterior):
    """ Override the method to ensure that a, b, c are not negative. """
    sample = super(BayesianLogisticWithGaussianNoise,
                   self)._draw_single_sample_from_posterior(posterior)
    if sample['a'] > 0 and sample['b'] > 0 and sample['c'] > 0 and sample['eta2'] > 0:
      return sample
    else:
      return self._draw_single_sample_from_posterior(posterior)

  # Instantiate y_giv_x_t functions ----------------------------------------------------
  def _eval_fXT(self, X, T):
    """ Evaluates f(x) = a/(1 + exp(b(x-c))). Here X can be a matrix but t is a single
        vector specifying one value for the parameter.
    """
    if self.t_domain.is_a_member(T):
      a = T[0]
      b = T[1]
      c = T[2]
    else:
      a = T[:, 0]
      b = T[:, 1]
      c = T[:, 2]
    X_ = np.array(X).ravel()
    return a/(1 + np.exp(b * (X_ - c)))

  def _sample_y_giv_x_t_single(self, num_samples, x, t):
    """ Samples y given x. """
    mean_val = self._eval_fXT(x, t)
    ret = mean_val + np.sqrt(t[3]) * np.random.normal(size=(num_samples,))
    return ret

  def eval_y_mean_giv_x_t(self, X, T):
    """ Evaluate the mean. """
    return list(self._eval_fXT(X, T))

  def eval_y_var_giv_x_t(self, X, T):
    """ Evaluate the variance. """
    if self.t_domain.is_a_member(T):
      T = np.array([T] * len(X))
    return T[:, 3]

  def eval_y_covar_giv_x(self, X):
    """ Evaluate the covariance. """
    return np.diag(self.eval_y_var_giv_x(X))

  def __str__(self):
    """ Returns a string representation. """
    return 'BayesianLogisticWithGaussian: %s'%(self.prior_info)


# An interface for Gaussian Processes --------------------------------------------
class GPonGrid(BayesianDiscriminativeModel):
  """ A class for GPs on a grid.
    This is just an interface in our framework to the actual GP object in gp/ that
    is doing the work.
  """

  def __init__(self, x_domain, t_domain, grid, gp_obj, *args, **kwargs):
    """ Constructor. """
    y_domain = EuclideanDomain([[-np.inf, np.inf]])
    self.grid = grid
    self.gp_obj = gp_obj
    super(GPonGrid, self).__init__(y_domain, x_domain, t_domain, *args, **kwargs)

  def _sample_y_giv_x_t_multiple(self, num_samples, x, t):
    """ Here t is assumed to be a tuple where the second is a GP object. """
    grid_data = t
    gp_obj = deepcopy(self.gp_obj)
    aug_X = gp_obj.X + list(grid_data[0])
    aug_Y = gp_obj.Y + list(grid_data[1])
    gp_obj.set_data(aug_X, aug_Y)
    return gp_obj.draw_samples(num_samples, [x])

  def _sample_y_giv_x_t_single(self, num_samples, x, t):
    """ Here t is assumed to be a tuple where the second is a GP object. """
    return self._sample_y_giv_x_t_multiple(num_samples, x, t)[0]

  def _sample_t_giv_data_in_xy_form_single(self, post_gp):
    """ Samples from the posterior. """
    grid_samples = post_gp.draw_samples(1, self.grid)[0]
    return self.grid, grid_samples

  def _sample_t_giv_data_in_xy_form(self, num_samples, X, Y):
    """ Samples from the posterior. """
    post_gp = deepcopy(self.gp_obj)
    post_gp.set_data(X, Y)
    return [self._sample_t_giv_data_in_xy_form_single(post_gp) for _ in
            range(num_samples)]

